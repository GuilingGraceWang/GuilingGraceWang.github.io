<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
  <head profile="http://gmpg.org/xfn/11">
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
 
<!-- Meta Images -->
    <!--<link rel="shortcut icon" href="http://iqua.ece.toronto.edu/wp-content/themes/iBlogPro/core/images/favicon-iqua.ico" type="image/x-icon" /> -->
    <link rel="shortcut icon" href="img/water.jpg" type="image/x-icon" />   
<!-- Title and External Script Integration -->
            <title>Guiling Wang</title>
        
<!-- Stylesheets -->
    <link rel="stylesheet" href="css/reset.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="css/wp_core.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="css/style.css" type="text/css" media="screen" />
    <link rel="stylesheet" href="css/pro.css" type="text/css" media="screen" />             

<style type="text/css"> 
    #nav ul{width: 950px;} 
    body{}
</style>

    </head>
<body class="page page-id-22 page-parent page-template page-template-page-highlight-full page-template-page-highlight-full-php">
 
<div id="page" class="fix" style="">
  <div id="wrapper" class="fix" >
    <div id="header" class="fix">
                    <a href="http://cs.njit.edu">
            <img class="headerimage" src="img/department.jpg" alt="NJIT"/>
            </a>
    </div><!-- /header -->
    <div id="nav" class="fix">
    <ul class="fix dropdown">
        <li class="page_item navfirst">
        
            <a class="home" href="index.html" title="Home" style="background-image: url('img/home-icon-trans.jpg');">
                Home    
            </a>
        </li>
<li class="page_item navfirst"><a href="research.html">Research</a>
</li>
<li class="page_item page-item-6 page_item_has_children"><a href="publications.html">Publications</a>
</li>
<li class="page_item page-item-29 page_item_has_children"><a href="teaching.html">Teaching</a>
</li>
<li class="page_item navfirst"><a href="service.html">Service</a>
</li>
<li class="page_item navfirst"><a href="people.html">People</a>
</li>
<!-- <li class="page_item navfirst"><a href="contact.html">Contact</a>
</li> -->
</ul>
    </div><!-- /nav -->
    <div id="container" class="fix ">
 
<div id="content">
 
            
            
    <div class="postwrap fix">
        
        <div class="post-607 page type-page status-publish hentry" id="post-607">
                            
                <div class="copy fix">
                                        <div class="textcontent">

<!-- <p>
<h3 class="fsub"><a href="https://scholar.google.com/citations?user=PJOGQc4AAAAJ&hl=en&authuser=1"><b>Google Scholar</b></a></h3>
</p> -->

<!--<p>
<h3 class="fsub"><a name="Research Interest" ></a><b>Research Interest</b></h3>
</p>
<ul>
<li><font face="Verdana" style="font-size: 10pt">Applied deep learning and machine learning</font></li>
<li><font face="Verdana" style="font-size: 10pt">Blockchain technologies</font></li>
<li><font face="Verdana" style="font-size: 10pt">FinTech (<a href="https://fintechlab-njit.netlify.app">FinTech Lab</a>)</font></li>
<li><font face="Verdana" style="font-size: 10pt">Mobile computing and IoT</font></li>
<li><font face="Verdana" style="font-size: 10pt">Intelligent transportation Systems</font></li>
</ul>

-->

<p>
    <h3 class="fsub"><a name="Research Projects"></a><b>Research Projects on Large Language Model and Natural Language Processing</b></h3>
</p>
<ul>
    <li><a href="#project1" font face="Verdana" style="font-size: 10pt">Enhancing Controllability and Explainability in Flowchart Understanding with LLMs</a></li>
    <li><a href="#project2" font face="Verdana" style="font-size: 10pt">Advancing Creative Problem-Solving in Mathematics with LLMs</a></li>
	<li><a href="#project3" font face="Verdana" style="font-size: 10pt">Advancing Logical Reasoning in LLMs with FaultyMath</a></li>
    <li><a href="#project4" font face="Verdana" style="font-size: 10pt">Revolutionizing Table Question Answering with Secure and Efficient LLM Solutions</a></li>
	<li><a href="#project5" font face="Verdana" style="font-size: 10pt">Data Augmentation for Text Classification with EASE</a></li>
    
    
</ul>


<div id="project1" class="project-detail">
    <div class="description">
        <h4>
            <a href="https://www.arxiv.org/abs/2412.16420" target="_blank">
                Enhancing Controllability and Explainability in Flowchart Understanding with LLMs
            </a>
        </h4>
        <p>
            Flowchart understanding, often reliant on vision-language models (VLMs), faces challenges in controllability and explainability. Users have limited ability to influence processing beyond input modification, and errors are difficult to trace due to opaque reasoning processes. To address these issues, we propose a two-stage framework <b>TextFlow</b>: a VLM converts flowchart images into customizable text representations, and an LLM performs reasoning and question-answering on the text. This approach enhances user control, isolates processing errors for improved explainability, and promotes modularity by enabling integration with advanced reasoning tools. The framework’s structured intermediate representations also provide a foundation for generalizing to other multimodal tasks, improving usability and reasoning capabilities.
        </p>
    </div>
    <div class="project-image">
        <img src="img/textflow.png" alt="TextFlow">
    </div>
</div>


<div id="project2" class="project-detail">
    <div class="description">
        <h4>
            <a href="https://arxiv.org/abs/2410.18336" target="_blank">
                Advancing Creative Problem-Solving in Mathematics with LLMs
            </a>
        </h4>
        <p>
            While research on Large Language Models (LLMs) has extensively explored their problem-solving capabilities, their potential for creativity in mathematical reasoning remains underexamined. To bridge this gap, we present <b>CreativeMath</b>, a framework designed to evaluate and enhance LLMs’ innovative reasoning abilities in mathematics. Published at AAAI 2025, CreativeMath introduces a benchmark comprising problems spanning middle school curricula to Olympic-level challenges, systematically assessing the creative problem-solving skills of LLMs. This study sheds light on both the strengths and limitations of LLMs in fostering mathematical creativity and offers a robust benchmark to advance our understanding of their cognitive potential.
        </p>
    </div>
    <div class="project-image">
        <img src="img/CreativeMath.png" alt="CreativeMath">
    </div>
</div>


<div id="project3" class="project-detail">
    <div class="description">
        <h4>
            <a href="https://arxiv.org/abs/2410.18921" target="_blank">
                Advancing Logical Reasoning in LLMs with FaultyMath
            </a>
        </h4>
        <p>
            Large Language Models (LLMs) excel at solving standard mathematical problems but often fail to detect logical inconsistencies, raising questions about their ability to reason beyond rote calculation. To address this, we present <b>FaultyMath</b>, a benchmark for evaluating LLMs' capacity to identify and reason about faulty math problems. FaultyMath encompasses diverse categories, including algebra and geometry, with varying difficulty levels and fault types such as contradictions and common-sense violations. It assesses LLMs’ performance in detecting flawed problems, incorporating hints, and providing reasoned explanations. This research underscores the limitations of current LLMs in logical reasoning and establishes a foundation for enhancing their cognitive capabilities, fostering more robust and trustworthy AI systems.
        </p>
    </div>
    <div class="project-image">
        <img src="img/FaultyMath.png" alt="FaultyMath">
    </div>
</div>


<div id="project4" class="project-detail">
    <div class="description">
        <h4>
            <a href="https://arxiv.org/abs/2401.15463" target="_blank">
                Revolutionizing Table Question Answering with Secure and Efficient LLM Solutions
            </a>
        </h4>
        <p>
            Table-based question answering with Large Language Models (LLMs) typically requires embedding entire tables into prompts. This approach faces challenges such as context window limitations, high computational costs, and data leakage risks, particularly for large tables. To address these issues, we propose <b>DataFrame QA</b>, a task and framework that generates Pandas queries for information retrieval and analysis on tables. By using only table column names and data types, this approach ensures data privacy, reduces token usage, and enhances efficiency, providing a foundation for secure and scalable LLM-powered tabular data analysis.
        </p>
    </div>
    <div class="project-image">
        <img src="img/DataFrame QA.png" alt="dataframeqa">
    </div>
</div>


<!-- Project Details -->
<div id="project5" class="project-detail">
    <div class="description">
        <h4>
            <a href="https://aclanthology.org/2023.icnlsp-1.35/" target="_blank">
                Data Augmentation for Text Classification with EASE
            </a>
        </h4>
        <p>
        In image classification, efficient data augmentation (DA) is easy with cropping, rotating, blurring etc. It works because a cropped/blurred “cat” is still a “cat”. In other words, the augmented sample does not require additional labeling as in most cases the augmented sample retains the original label. In text classification (TC) existing methods have random insertion, deletion of random words or punctuation, but the semantics change very easily.  Therefore, these methods that use the same label for the augmented samples simply inject more noise in many cases. Moreover, acquiring new labels for the augmented sample requires training on the original data first to get a good estimate of the new labels. In this work, we present EASE, a simple but dependable DA technique for TC that has four easy steps: Extract Units, Acquire Labels, Sift and Employ. We extract meaningful units as augmented samples from original data samples and use powerful tools to acquire labels for them before they are sifted and merged. Previous DA techniques, like EDA and AEDA, excel with sequential models but struggle with transformer-based models that heavily rely on token order. EASE, in contrast, performs well with these models, demonstrating stability, speed, and minimal adverse effects. We tested our intuitive method on multiple challenging datasets sensitive to augmentation, and experimental results have indicated the efficacy of DA with EASE.
        </p>
    </div>
    <div class="project-image">
        <img src="img/ease.png" alt="ease">
    </div>
</div>








 
</body>
</html>
<!-- Performance optimized by W3 Total Cache. Learn more: http://www.w3-edge.com/wordpress-plugins/
 
Page Caching using disk: enhanced
 
 Served from: iqua.ece.toronto.edu @ 2015-02-14 01:07:43 by W3 Total Cache -->
